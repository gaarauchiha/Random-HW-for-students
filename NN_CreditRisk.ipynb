{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da155d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6339758\n",
      "accuracy_baseline: 0.5\n",
      "auc: 0.684344\n",
      "auc_precision_recall: 0.6638764\n",
      "average_loss: 0.6440559\n",
      "global_step: 60\n",
      "label/mean: 0.5\n",
      "loss: 0.6440559\n",
      "precision: 0.62323457\n",
      "prediction/mean: 0.5219454\n",
      "recall: 0.6775562\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.feature_column as fc\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import recall_score\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "import functools\n",
    "random.seed(10)\n",
    "\n",
    "# Load and preprocess data\n",
    "data = pd.read_csv('input_file_2.csv', sep=',', index_col=0)\n",
    "data['issue_d'] = pd.to_datetime(data['issue_d'])\n",
    "\n",
    "# Split data into training and test sets\n",
    "train_df = data.loc[data['issue_d'] < data['issue_d'].quantile(0.75)]\n",
    "test_df = data.loc[data['issue_d'] >= data['issue_d'].quantile(0.75)]\n",
    "\n",
    "# Drop the 'issue_d' column\n",
    "train_df = train_df.drop('issue_d', axis=1)\n",
    "test_df = test_df.drop('issue_d', axis=1)\n",
    "\n",
    "# Define columns to scale\n",
    "all_cols = list(train_df.columns)\n",
    "all_cols.remove('charged_off')\n",
    "to_drop_categorical = ['home_ownership', 'verification_status', 'purpose', 'application_type']\n",
    "for i in to_drop_categorical:\n",
    "    all_cols.remove(i)\n",
    "\n",
    "# Fill null values by mean imputation\n",
    "train_df[all_cols] = train_df[all_cols].fillna(train_df[all_cols].mean())\n",
    "test_df[all_cols] = test_df[all_cols].fillna(train_df[all_cols].mean())\n",
    "\n",
    "# Scale values of numerical columns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(copy=False)\n",
    "train_df[all_cols] = scaler.fit_transform(train_df[all_cols])\n",
    "test_df[all_cols] = scaler.transform(test_df[all_cols])\n",
    "\n",
    "# Balance classes for training and testing\n",
    "train_dat_1s = train_df[train_df['charged_off'] == 1]\n",
    "train_dat_0s = train_df[train_df['charged_off'] == 0]\n",
    "keep_0s = train_dat_0s.sample(frac=train_dat_1s.shape[0]/train_dat_0s.shape[0])\n",
    "train_df = pd.concat([keep_0s,train_dat_1s],axis=0)\n",
    "\n",
    "test_dat_1s = test_df[test_df['charged_off'] == 1]\n",
    "test_dat_0s = test_df[test_df['charged_off'] == 0]\n",
    "keep_0s = test_dat_0s.sample(frac=test_dat_1s.shape[0]/test_dat_0s.shape[0])\n",
    "test_df = pd.concat([keep_0s,test_dat_1s],axis=0)\n",
    "\n",
    "# Define input function\n",
    "def easy_input_function(df, label_key, num_epochs, shuffle, batch_size):\n",
    "  label = df[label_key]\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(df),label))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(10000)\n",
    "  ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "  return ds\n",
    "\n",
    "# Define training and test input functions\n",
    "train_inpf = functools.partial(easy_input_function, train_df, label_key='charged_off',  num_epochs=5, shuffle=True, batch_size=20000)\n",
    "test_inpf = functools.partial(easy_input_function, test_df, label_key='charged_off', num_epochs=1, shuffle=False, batch_size=200000)\n",
    "\n",
    "# Define all numeric columns\n",
    "loan_amnt = fc.numeric_column('loan_amnt')\n",
    "term = fc.numeric_column('term')\n",
    "installment = fc.numeric_column('installment')\n",
    "emp_length = fc.numeric_column('emp_length')\n",
    "dti = fc.numeric_column('dti')\n",
    "earliest_cr_line = fc.numeric_column('earliest_cr_line')\n",
    "open_acc = fc.numeric_column('open_acc')\n",
    "pub_rec = fc.numeric_column('pub_rec')\n",
    "revol_util = fc.numeric_column('revol_util')\n",
    "total_acc = fc.numeric_column('total_acc')\n",
    "mort_acc = fc.numeric_column('mort_acc')\n",
    "pub_rec_bankruptcies = fc.numeric_column('pub_rec_bankruptcies')\n",
    "log_annual_inc = fc.numeric_column('log_annual_inc')\n",
    "fico_score = fc.numeric_column('fico_score')\n",
    "log_revol_bal = fc.numeric_column('log_revol_bal')\n",
    "\n",
    "my_numeric_columns = [loan_amnt, term, installment, emp_length, dti, earliest_cr_line, open_acc, pub_rec, revol_util, total_acc, mort_acc, pub_rec_bankruptcies, log_annual_inc, fico_score, log_revol_bal]\n",
    "\n",
    "# Define metrics\n",
    "def metric_auc(labels, predictions):\n",
    "    return {\n",
    "        'auc_precision_recall': tf.metrics.AUC(\n",
    "            labels=labels, predictions=predictions['logistic'], num_thresholds=200,\n",
    "            curve='PR', summation_method='careful_interpolation')\n",
    "    }\n",
    "\n",
    "# Train model on all numeric columns\n",
    "classifier = tf.estimator.LinearClassifier(feature_columns=my_numeric_columns)\n",
    "#classifier = classifier.add_metrics(metric_auc)\n",
    "classifier.train(train_inpf)\n",
    "result = classifier.evaluate(test_inpf)\n",
    "\n",
    "# Print results\n",
    "clear_output()\n",
    "for key,value in sorted(result.items()):\n",
    "  print('%s: %s' % (key, value))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef83c145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
